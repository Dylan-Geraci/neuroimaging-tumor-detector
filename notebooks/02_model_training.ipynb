{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "669c4aeb797844aa978a9076b109acf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9dd8db4dd8d740509c55c3e2ca127b65",
              "IPY_MODEL_be4ce408a5dd4d5db069801ec0ca2b64",
              "IPY_MODEL_6ec3679c64e74a00b0ff2d3cd661bbdb"
            ],
            "layout": "IPY_MODEL_e8dfc43488ab4ff1b9e01dbb3fae065b"
          }
        },
        "9dd8db4dd8d740509c55c3e2ca127b65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22f63dd53ff24200945879e0fc6d5ebc",
            "placeholder": "​",
            "style": "IPY_MODEL_3bc3d9debf0c4058b41cc0fed57d8a07",
            "value": "model.safetensors: 100%"
          }
        },
        "be4ce408a5dd4d5db069801ec0ca2b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_024a6b0bb484409b9a552d3bd1530b75",
            "max": 21355344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41ecb3907b1544aab0a8003ee2c9680e",
            "value": 21355344
          }
        },
        "6ec3679c64e74a00b0ff2d3cd661bbdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f75cec6b44f4637a75d7d1a31b0e130",
            "placeholder": "​",
            "style": "IPY_MODEL_941f299b07a14072a6ea354f33ecf0fe",
            "value": " 21.4M/21.4M [00:00&lt;00:00, 42.3MB/s]"
          }
        },
        "e8dfc43488ab4ff1b9e01dbb3fae065b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f63dd53ff24200945879e0fc6d5ebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bc3d9debf0c4058b41cc0fed57d8a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "024a6b0bb484409b9a552d3bd1530b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41ecb3907b1544aab0a8003ee2c9680e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f75cec6b44f4637a75d7d1a31b0e130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "941f299b07a14072a6ea354f33ecf0fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dylan-Geraci/neuroimaging-tumor-detector/blob/main/notebooks/02_model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "DJ7_x9M-Ji5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Setup"
      ],
      "metadata": {
        "id": "xUgARUCOJt7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "npv4PSqgKA4D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7f8UXfqI3O4x"
      },
      "outputs": [],
      "source": [
        "# --- Standard ---\n",
        "import os, json, math, time\n",
        "from collections import Counter\n",
        "\n",
        "# --- Numerical / data ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Imaging & plotting ---\n",
        "from PIL import Image\n",
        "\n",
        "# --- Torch / ML ---\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# --- Metrics ---\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# --- Vision ---\n",
        "from torchvision import transforms\n",
        "\n",
        "# --- Pretrained models ---\n",
        "import timm\n",
        "\n",
        "# --- Google Drive ---\n",
        "from google.colab import drive\n",
        "\n",
        "import time, json, torch\n",
        "from torch.amp import autocast, GradScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Training Data Path"
      ],
      "metadata": {
        "id": "5CPczaCDJz2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "TRAIN_PATH = \"/content/drive/MyDrive/neuro-imaging/data/Training\""
      ],
      "metadata": {
        "id": "SqZB24pgJzee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1362ed9-9379-4883-bd3e-2e228d529861"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "USE_SAVED_SPLITS = False\n",
        "SPLITS_DIR = \"/content/drive/MyDrive/neuro-imaging/splits\""
      ],
      "metadata": {
        "id": "mTKcqorcS7mD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Path and Constants"
      ],
      "metadata": {
        "id": "flyOUPy_YeLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = \"/content/drive/MyDrive/neuro-imaging/data/Training\"\n",
        "SPLITS_DIR = \"/content/drive/MyDrive/neuro-imaging/splits\"\n",
        "OUT_DIR    = \"/content/drive/MyDrive/neuro-imaging/models\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "LR = 3e-4\n",
        "EPOCHS = 10\n",
        "PATIENCE = 2\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "zIY6rvRiYggv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reproducing"
      ],
      "metadata": {
        "id": "fNk99AnOYn3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=SEED):\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5gyhzb3Yqs9",
        "outputId": "2c4588ec-55fb-43f1-a885-5bdd3efcfe32"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Splits and Class Maps"
      ],
      "metadata": {
        "id": "ehSgdCCHY15I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _read_paths(txt_path):\n",
        "    with open(txt_path, \"r\") as f:\n",
        "        return [ln.strip() for ln in f if ln.strip()]\n",
        "\n",
        "with open(os.path.join(SPLITS_DIR, \"class_to_idx.json\"), \"r\") as f:\n",
        "    class_to_idx = json.load(f)\n",
        "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "num_classes = len(class_to_idx)\n",
        "print(\"Classes:\", [idx_to_class[i] for i in range(num_classes)])\n",
        "\n",
        "train_paths = _read_paths(os.path.join(SPLITS_DIR, \"train.txt\"))\n",
        "val_paths   = _read_paths(os.path.join(SPLITS_DIR, \"val.txt\"))\n",
        "print(f\"Loaded {len(train_paths)} train, {len(val_paths)} val files\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE0C_9ADY5aH",
        "outputId": "c72b8068-eac1-4b08-b709-9a899ea503b2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
            "Loaded 4855 train, 857 val files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transforms"
      ],
      "metadata": {
        "id": "XMNmQVlYgjx3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_tfms = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "D7h-8FpGgl7p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset from path list"
      ],
      "metadata": {
        "id": "TGQ57dOcgn3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PathDataset(Dataset):\n",
        "    def __init__(self, paths, class_to_idx, transform=None):\n",
        "        self.paths = paths\n",
        "        self.class_to_idx = class_to_idx\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        p = self.paths[i]\n",
        "        cls_name = os.path.basename(os.path.dirname(p))\n",
        "        y = self.class_to_idx[cls_name]\n",
        "        img = Image.open(p)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, y\n",
        "\n",
        "train_ds = PathDataset(train_paths, class_to_idx, train_tfms)\n",
        "val_ds   = PathDataset(val_paths,   class_to_idx, val_tfms)\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
      ],
      "metadata": {
        "id": "W1rgcAdAgnVL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class weights (handle imbalances)"
      ],
      "metadata": {
        "id": "uEYti79Ki6cY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_counts = Counter([os.path.basename(os.path.dirname(p)) for p in train_paths])\n",
        "counts_by_idx = np.array([train_counts[idx_to_class[i]] for i in range(num_classes)], dtype=np.float32)\n",
        "weights = (len(train_paths) / (num_classes * counts_by_idx))\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32, device=device)\n",
        "print(\"Class weights:\", weights.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCTfEsX_i4la",
        "outputId": "d9890ec6-123e-4e87-b994-8d876f15294f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights: [1.080810308456421, 1.0665642023086548, 0.8950958847999573, 0.980411946773529]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model, loss, optimizer, scaler"
      ],
      "metadata": {
        "id": "wgmV7uA7jGzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = timm.create_model(\"efficientnet_b0\", pretrained=True, num_classes=num_classes)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "669c4aeb797844aa978a9076b109acf8",
            "9dd8db4dd8d740509c55c3e2ca127b65",
            "be4ce408a5dd4d5db069801ec0ca2b64",
            "6ec3679c64e74a00b0ff2d3cd661bbdb",
            "e8dfc43488ab4ff1b9e01dbb3fae065b",
            "22f63dd53ff24200945879e0fc6d5ebc",
            "3bc3d9debf0c4058b41cc0fed57d8a07",
            "024a6b0bb484409b9a552d3bd1530b75",
            "41ecb3907b1544aab0a8003ee2c9680e",
            "4f75cec6b44f4637a75d7d1a31b0e130",
            "941f299b07a14072a6ea354f33ecf0fe"
          ]
        },
        "id": "6X4ZOL8ujI1k",
        "outputId": "720e9661-3f80-4ecd-9005-7faea7b2cbe8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "669c4aeb797844aa978a9076b109acf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3194161557.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train / eval helpers"
      ],
      "metadata": {
        "id": "nJtMe3KhjTD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds, all_targets = [], []\n",
        "    total_loss = 0.0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_targets.append(y.cpu().numpy())\n",
        "\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_targets = np.concatenate(all_targets)\n",
        "    val_loss = total_loss / len(loader.dataset)\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    f1_macro = f1_score(all_targets, all_preds, average=\"macro\")\n",
        "    return {\"loss\": val_loss, \"acc\": acc, \"f1_macro\": f1_macro}\n",
        "\n",
        "def train_one_epoch(model, loader, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(device.type==\"cuda\")):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "    return total_loss / len(loader.dataset)"
      ],
      "metadata": {
        "id": "T4suZtzJjUVR"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop with early stopping on val macro-F1"
      ],
      "metadata": {
        "id": "Q2X7U0twjZqy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copying data to local"
      ],
      "metadata": {
        "id": "9YCHEElu2Tvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, os, subprocess, textwrap\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    try:\n",
        "        print(subprocess.check_output([\"nvidia-smi\"], text=True))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "!mkdir -p /content/data/Training\n",
        "!rsync -ah --delete --info=progress2 \"/content/drive/MyDrive/neuro-imaging/data/Training/\" \"/content/data/Training/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyHIs7I6jcqD",
        "outputId": "336ff08f-3b51-404e-d2e6-ade7f4aabc7a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "Mon Aug 25 21:00:13 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0             28W /   70W |     136MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "        132.45M 100%   86.26kB/s    0:24:59 (xfr#5712, to-chk=0/5717)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, json, numpy as np, torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "PIN = device.type == \"cuda\"\n",
        "NUM_WORKERS = 2 if PIN else 0\n",
        "print(\"Device:\", device)\n",
        "\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/neuro-imaging/data/Training\"\n",
        "LOCAL_ROOT = \"/content/data/Training\"\n",
        "if os.path.isdir(LOCAL_ROOT):\n",
        "    train_paths = [p.replace(DRIVE_ROOT, LOCAL_ROOT) for p in train_paths]\n",
        "    val_paths   = [p.replace(DRIVE_ROOT, LOCAL_ROOT) for p in val_paths]\n",
        "    train_ds.paths, val_ds.paths = train_paths, val_paths\n",
        "    print(\"Using LOCAL data:\", LOCAL_ROOT)\n",
        "\n",
        "USE_LIGHT_MODEL_ON_CPU = True\n",
        "if device.type != \"cuda\" and USE_LIGHT_MODEL_ON_CPU:\n",
        "    import timm\n",
        "    model = timm.create_model(\"mobilenetv3_small_075\", pretrained=True, num_classes=len(class_to_idx)).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
        "    print(\"Switched to MobileNetV3 small for CPU speed.\")\n",
        "\n",
        "dl_kwargs = dict(batch_size=BATCH_SIZE, pin_memory=PIN)\n",
        "if NUM_WORKERS > 0:\n",
        "    dl_kwargs.update(num_workers=NUM_WORKERS, persistent_workers=True, prefetch_factor=2)\n",
        "else:\n",
        "    dl_kwargs.update(num_workers=0)\n",
        "train_dl = DataLoader(train_ds, shuffle=True,  **dl_kwargs)\n",
        "val_dl   = DataLoader(val_ds,   shuffle=False, **dl_kwargs)\n",
        "\n",
        "scaler = GradScaler(enabled=PIN)\n",
        "\n",
        "#Helpers\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    from sklearn.metrics import accuracy_score, f1_score\n",
        "    model.eval()\n",
        "    total_loss, preds_all, targs_all = 0.0, [], []\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=PIN); y = y.to(device, non_blocking=PIN)\n",
        "        with autocast(device_type=\"cuda\", enabled=PIN):\n",
        "            logits = model(x); loss = criterion(logits, y)\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        preds_all.append(torch.argmax(logits, 1).cpu().numpy())\n",
        "        targs_all.append(y.cpu().numpy())\n",
        "    preds = np.concatenate(preds_all); targs = np.concatenate(targs_all)\n",
        "    return {\"loss\": total_loss/len(loader.dataset),\n",
        "            \"acc\": float((preds==targs).mean()),\n",
        "            \"f1_macro\": float(f1_score(targs, preds, average=\"macro\"))}\n",
        "\n",
        "def train_one_epoch(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for x, y in loader:\n",
        "        x = x.to(device, non_blocking=PIN); y = y.to(device, non_blocking=PIN)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with autocast(device_type=\"cuda\", enabled=PIN):\n",
        "            logits = model(x); loss = criterion(logits, y)\n",
        "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "BEST_PATH = os.path.join(OUT_DIR, \"best.pt\")\n",
        "LAST_PATH = os.path.join(OUT_DIR, \"last.pt\")\n",
        "best = {\"f1\": -1.0, \"epoch\": 0}\n",
        "\n",
        "start_epoch = 1\n",
        "if os.path.exists(LAST_PATH):\n",
        "    try:\n",
        "        ckpt = torch.load(LAST_PATH, map_location=device)\n",
        "        model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "        start_epoch = int(ckpt.get(\"epoch\", 0)) + 1\n",
        "        best[\"f1\"] = float(ckpt.get(\"best_f1\", -1.0))\n",
        "        best[\"epoch\"] = int(ckpt.get(\"best_epoch\", 0))\n",
        "        print(f\"Resumed from epoch {start_epoch-1} (best F1={best['f1']:.4f})\")\n",
        "    except Exception as e:\n",
        "        print(\"Resume failed (starting fresh):\", e)\n",
        "\n",
        "EPOCHS_RUN = min(EPOCHS, 6)\n",
        "PATIENCE = 1\n",
        "MAX_MINUTES = 20\n",
        "t0 = time.time()\n",
        "history = []\n",
        "patience_left = PATIENCE\n",
        "\n",
        "try:\n",
        "    for epoch in range(start_epoch, start_epoch + EPOCHS_RUN):\n",
        "        train_loss = train_one_epoch(model, train_dl)\n",
        "        val_metrics = evaluate(model, val_dl)\n",
        "        log = {\"epoch\": epoch,\n",
        "               \"train_loss\": float(train_loss),\n",
        "               \"val_loss\": float(val_metrics[\"loss\"]),\n",
        "               \"val_acc\": float(val_metrics[\"acc\"]),\n",
        "               \"val_f1_macro\": float(val_metrics[\"f1_macro\"]),\n",
        "               \"time_sec\": float(time.time()-t0)}\n",
        "        history.append(log); print(log)\n",
        "\n",
        "        torch.save({\"model_state_dict\": model.state_dict(),\n",
        "                    \"epoch\": epoch,\n",
        "                    \"best_f1\": best[\"f1\"],\n",
        "                    \"best_epoch\": best[\"epoch\"]}, LAST_PATH)\n",
        "\n",
        "        if val_metrics[\"f1_macro\"] > best[\"f1\"] + 1e-6:\n",
        "            best.update({\"f1\": val_metrics[\"f1_macro\"], \"epoch\": epoch})\n",
        "            torch.save({\"model_state_dict\": model.state_dict(),\n",
        "                        \"class_to_idx\": class_to_idx,\n",
        "                        \"img_size\": IMG_SIZE},\n",
        "                       BEST_PATH)\n",
        "            patience_left = PATIENCE\n",
        "        else:\n",
        "            patience_left -= 1\n",
        "\n",
        "        if patience_left <= 0:\n",
        "            print(f\"Early stopping at epoch {epoch} (best epoch {best['epoch']}, F1={best['f1']:.4f})\")\n",
        "            break\n",
        "\n",
        "        if (time.time() - t0) > MAX_MINUTES * 60:\n",
        "            print(f\"Time cap reached (~{MAX_MINUTES} min).\")\n",
        "            break\n",
        "\n",
        "finally:\n",
        "    with open(os.path.join(OUT_DIR, \"train_log.json\"), \"w\") as f:\n",
        "        json.dump(history, f, indent=2)\n",
        "\n",
        "print(\"Best:\", best, \"| Checkpoints:\", {\"best\": os.path.basename(BEST_PATH), \"last\": os.path.basename(LAST_PATH)})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aJkJ9Tw2RtQ",
        "outputId": "b9c4b424-35d9-451e-e634-e8e50fb5d241"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Using LOCAL data: /content/data/Training\n",
            "Resumed from epoch 4 (best F1=0.9858)\n",
            "{'epoch': 5, 'train_loss': 0.08445280406185993, 'val_loss': 0.09135677819542343, 'val_acc': 0.9731621936989499, 'val_f1_macro': 0.9720730465349766, 'time_sec': 56.08293557167053}\n",
            "Early stopping at epoch 5 (best epoch 3, F1=0.9858)\n",
            "Best: {'f1': 0.985811140155392, 'epoch': 3} | Checkpoints: {'best': 'best.pt', 'last': 'last.pt'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Trained Model and Testing\n",
        "You can starting running from here and libraries at the top"
      ],
      "metadata": {
        "id": "cg7HNYb5Ynhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load best checkpoint"
      ],
      "metadata": {
        "id": "AgNjL1owYcak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt = torch.load(os.path.join(OUT_DIR, \"best.pt\"), map_location=device)\n",
        "model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZapwwMRBUXuJ",
        "outputId": "1d978ef9-81cb-4173-946c-1b80533fc6ea"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNormAct2d(\n",
              "    32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (drop): Identity()\n",
              "    (act): SiLU(inplace=True)\n",
              "  )\n",
              "  (blocks): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): DepthwiseSeparableConv(\n",
              "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (2): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (4): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): InvertedResidual(\n",
              "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (2): InvertedResidual(\n",
              "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (3): InvertedResidual(\n",
              "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (6): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNormAct2d(\n",
              "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (bn2): BatchNormAct2d(\n",
              "          1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (aa): Identity()\n",
              "        (se): SqueezeExcite(\n",
              "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act1): SiLU(inplace=True)\n",
              "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (gate): Sigmoid()\n",
              "        )\n",
              "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNormAct2d(\n",
              "          320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "          (drop): Identity()\n",
              "          (act): Identity()\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (bn2): BatchNormAct2d(\n",
              "    1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "    (drop): Identity()\n",
              "    (act): SiLU(inplace=True)\n",
              "  )\n",
              "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "  (classifier): Linear(in_features=1280, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict on the validation set (no augmentation)"
      ],
      "metadata": {
        "id": "dKaBEuzMYji_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds, targs, files = [], [], []\n",
        "for p in val_paths:\n",
        "    img = Image.open(p)\n",
        "    x = val_tfms(img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        pred = int(logits.argmax(1).item())\n",
        "    preds.append(pred)\n",
        "    cls_name = os.path.basename(os.path.dirname(p))\n",
        "    targs.append(int(class_to_idx[cls_name]))\n",
        "    files.append(p)"
      ],
      "metadata": {
        "id": "w4quXn5qYklo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics"
      ],
      "metadata": {
        "id": "PyTXv5-4Yzyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "target_names = [idx_to_class[i] for i in range(num_classes)]\n",
        "print(classification_report(targs, preds, target_names=target_names, digits=4))\n",
        "\n",
        "cm = confusion_matrix(targs, preds, labels=list(range(num_classes)))\n",
        "import numpy as np, matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.imshow(cm, interpolation=\"nearest\")\n",
        "plt.title(\"Confusion Matrix (val)\")\n",
        "plt.colorbar()\n",
        "ticks = np.arange(num_classes)\n",
        "plt.xticks(ticks, target_names, rotation=45, ha=\"right\")\n",
        "plt.yticks(ticks, target_names)\n",
        "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUT_DIR, \"confusion_matrix_val.png\"), dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "XbpgjnSTY0GI",
        "outputId": "f45ff329-fa53-4237-c031-6ecf281f5506"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      glioma     1.0000    0.9798    0.9898       198\n",
            "  meningioma     0.9614    0.9900    0.9755       201\n",
            "     notumor     0.9916    0.9874    0.9895       239\n",
            "   pituitary     0.9908    0.9863    0.9886       219\n",
            "\n",
            "    accuracy                         0.9860       857\n",
            "   macro avg     0.9859    0.9859    0.9858       857\n",
            "weighted avg     0.9862    0.9860    0.9860       857\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save per-file predictions and misclassifications"
      ],
      "metadata": {
        "id": "N1Kh2NoCZCpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_preds = pd.DataFrame({\n",
        "    \"file\": files,\n",
        "    \"true\": [idx_to_class[t] for t in targs],\n",
        "    \"pred\": [idx_to_class[p] for p in preds],\n",
        "})\n",
        "df_preds.to_csv(os.path.join(OUT_DIR, \"val_predictions.csv\"), index=False)\n",
        "df_preds[df_preds.true != df_preds.pred].to_csv(os.path.join(OUT_DIR, \"val_misclassified.csv\"), index=False)"
      ],
      "metadata": {
        "id": "2JMmm_tQZC87"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}